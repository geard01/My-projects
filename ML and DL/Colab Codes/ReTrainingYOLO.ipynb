{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"L4","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"pe4E13nZGGMd","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1747644409604,"user_tz":-120,"elapsed":4277,"user":{"displayName":"Gruppo ML","userId":"14938435567714989624"}},"outputId":"87d4fe3c-68c3-43cc-d34b-0bf33bc05fc5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.139)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"]}],"source":["import os\n","import torch\n","!pip install ultralytics\n","from ultralytics import YOLO\n","from google.colab import drive\n","import numpy as np\n","import random"]},{"cell_type":"code","source":["def set_seed(seed=42):\n","    random.seed(seed)  # Python\n","    np.random.seed(seed)  # NumPy\n","    torch.manual_seed(seed)  # CPU\n","    torch.cuda.manual_seed(seed)  # GPU singola\n","    torch.cuda.manual_seed_all(seed)  # Tutte le GPU\n","\n","    # Comportamento deterministico per reproducibilitÃ \n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","if torch.cuda.is_available():\n","  device = \"cuda\"\n","else:\n","  device = \"cpu\"\n","\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xJtNlvHamxR0","executionInfo":{"status":"ok","timestamp":1747644415862,"user_tz":-120,"elapsed":3687,"user":{"displayName":"Gruppo ML","userId":"14938435567714989624"}},"outputId":"b55dfa95-efd6-4fcd-b597-b203d733f18b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["set_seed(42)\n","id_modello_partenza = 10 # id first pretrained model\n","n_epochs = 20 # how many pretrained models\n","\n","\n","if id_modello_partenza > 0:\n","  model = YOLO(f\"/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_{id_modello_partenza}.pt\") # Riprendo da ultimo modello ritrainato\n","  start_epoch = id_modello_partenza\n","else:\n","  model = YOLO('yolov8n.pt')\n","\n","model.to(device)\n","\n","for i in range(n_epochs):\n","  results = model.train(data=\"/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml\",epochs=1,imgsz=640,save=False,verbose=True)\n","  model.save(f\"/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_{i+id_modello_partenza+1}.pt\")"],"metadata":{"id":"6xmwU02mGLhg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747650136529,"user_tz":-120,"elapsed":5717453,"user":{"displayName":"Gruppo ML","userId":"14938435567714989624"}},"outputId":"519835a7-3402-4de5-a91a-88ccb0a82518"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 0.5Â±0.0 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 1.6Â±1.2 ms, read: 0.4Â±0.3 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1       2.1G     0.4378     0.6732     0.8365         15        640: 100%|ââââââââââ| 150/150 [01:00<00:00,  2.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [32:42<00:00,  4.68s/it]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.975      0.968      0.991      0.828\n","\n","1 epochs completed in 0.563 hours.\n","Optimizer stripped from runs/detect/train2/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.974      0.968      0.991      0.828\n","                obj_01       1050       1050      0.989      0.978      0.994       0.85\n","                obj_02       1031       1031      0.978      0.995      0.994      0.813\n","                obj_04       1020       1020      0.935      0.985       0.99      0.793\n","                obj_05       1016       1016      0.943      0.989      0.992      0.824\n","                obj_06       1002       1002      0.985      0.841      0.972      0.832\n","                obj_08       1009       1009      0.971      0.969       0.99      0.845\n","                obj_09       1065       1065      0.964      0.936      0.984      0.835\n","                obj_10       1065       1065      0.967      0.997      0.995      0.869\n","                obj_11       1036       1036      0.979      0.968      0.992      0.793\n","                obj_12       1051       1051      0.986      0.982      0.994      0.855\n","                obj_13        979        979      0.998       0.96      0.995        0.8\n","                obj_14       1042       1042      0.986      0.996      0.995      0.852\n","                obj_15       1041       1041      0.984      0.988      0.994      0.803\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train22, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 207.9Â±73.6 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.7Â±0.6 ms, read: 129.2Â±118.2 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train22/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train22\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.07G     0.4529     0.6462     0.8384         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:09<00:00,  6.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.973      0.964      0.991      0.834\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train22/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train22/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train22/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:02<00:00,  6.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.973      0.965      0.991      0.833\n","                obj_01       1050       1050      0.962       0.99      0.994      0.863\n","                obj_02       1031       1031      0.962       0.98      0.992      0.803\n","                obj_04       1020       1020       0.95      0.987      0.992      0.775\n","                obj_05       1016       1016      0.988      0.973      0.994      0.854\n","                obj_06       1002       1002      0.894      0.986      0.992      0.849\n","                obj_08       1009       1009      0.994      0.851      0.972      0.823\n","                obj_09       1065       1065      0.947      0.996      0.994      0.874\n","                obj_10       1065       1065      0.992       0.99      0.995       0.87\n","                obj_11       1036       1036      0.978      0.969      0.992      0.795\n","                obj_12       1051       1051      0.998      0.905      0.993      0.841\n","                obj_13        979        979          1      0.994      0.995      0.829\n","                obj_14       1042       1042      0.996      0.989      0.995       0.86\n","                obj_15       1041       1041      0.988      0.931      0.989      0.799\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train22\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.0 ms, read: 225.0Â±82.9 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 189.3Â±38.9 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.4232      0.599     0.8323         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.978      0.967      0.993      0.845\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.976      0.969      0.993      0.845\n","                obj_01       1050       1050      0.991      0.968      0.994      0.857\n","                obj_02       1031       1031      0.988       0.98      0.993      0.826\n","                obj_04       1020       1020      0.911      0.997      0.994      0.793\n","                obj_05       1016       1016      0.999      0.945      0.994      0.868\n","                obj_06       1002       1002      0.968      0.954       0.99      0.854\n","                obj_08       1009       1009      0.984      0.926      0.984      0.843\n","                obj_09       1065       1065      0.919      0.998      0.994      0.871\n","                obj_10       1065       1065      0.982      0.994      0.995      0.884\n","                obj_11       1036       1036      0.984      0.967      0.993      0.798\n","                obj_12       1051       1051      0.998      0.911      0.994       0.86\n","                obj_13        979        979          1      0.972      0.995      0.827\n","                obj_14       1042       1042      0.982      0.993      0.995       0.86\n","                obj_15       1041       1041      0.979      0.986      0.994      0.844\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train2222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.0 ms, read: 209.5Â±74.7 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.3 ms, read: 156.8Â±78.7 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.4101     0.5679     0.8293         15        640: 100%|ââââââââââ| 150/150 [00:18<00:00,  8.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.976      0.973      0.993      0.844\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train2222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.976      0.973      0.993      0.844\n","                obj_01       1050       1050      0.996      0.956      0.994       0.85\n","                obj_02       1031       1031      0.985       0.98      0.993      0.829\n","                obj_04       1020       1020      0.936      0.983      0.991      0.813\n","                obj_05       1016       1016      0.952      0.999      0.993      0.867\n","                obj_06       1002       1002      0.957       0.98      0.989      0.852\n","                obj_08       1009       1009       0.98      0.935      0.988      0.854\n","                obj_09       1065       1065      0.962      0.998      0.994      0.863\n","                obj_10       1065       1065      0.958      0.995      0.995      0.884\n","                obj_11       1036       1036      0.969       0.98      0.993      0.788\n","                obj_12       1051       1051      0.999      0.934      0.995      0.855\n","                obj_13        979        979          1      0.968      0.995      0.823\n","                obj_14       1042       1042      0.992      0.997      0.995      0.861\n","                obj_15       1041       1041      0.995      0.945      0.994      0.835\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train22222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.4Â±0.0 ms, read: 185.8Â±70.3 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 247.3Â±47.2 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train22222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train22222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3991     0.5371     0.8263         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.965      0.972       0.99       0.82\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train22222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train22222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train22222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:04<00:00,  6.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.965      0.973      0.991       0.82\n","                obj_01       1050       1050      0.988      0.942      0.993      0.845\n","                obj_02       1031       1031      0.991      0.952      0.993      0.812\n","                obj_04       1020       1020      0.895      0.995      0.989      0.779\n","                obj_05       1016       1016      0.961      0.982      0.992      0.824\n","                obj_06       1002       1002      0.977      0.979      0.993      0.832\n","                obj_08       1009       1009      0.957      0.872      0.968      0.812\n","                obj_09       1065       1065      0.953      0.995      0.992      0.835\n","                obj_10       1065       1065      0.968      0.993      0.994      0.848\n","                obj_11       1036       1036      0.932      0.987      0.989      0.769\n","                obj_12       1051       1051      0.959      0.996      0.994      0.834\n","                obj_13        979        979      0.996      0.993      0.995      0.814\n","                obj_14       1042       1042      0.998      0.982      0.995      0.849\n","                obj_15       1041       1041      0.968      0.973      0.992      0.802\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train22222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.1 ms, read: 231.9Â±85.1 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 190.2Â±33.9 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3909     0.5121     0.8261         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.967      0.971      0.992      0.815\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.967      0.972      0.992      0.815\n","                obj_01       1050       1050       0.99      0.961      0.994      0.822\n","                obj_02       1031       1031      0.988       0.97      0.994      0.794\n","                obj_04       1020       1020       0.92      0.997      0.988      0.783\n","                obj_05       1016       1016      0.992      0.986      0.994      0.822\n","                obj_06       1002       1002       0.98      0.968      0.992      0.846\n","                obj_08       1009       1009      0.865      0.989      0.985      0.827\n","                obj_09       1065       1065      0.969      0.998      0.994      0.845\n","                obj_10       1065       1065      0.952      0.996      0.994      0.858\n","                obj_11       1036       1036      0.953      0.956      0.988      0.727\n","                obj_12       1051       1051      0.992      0.986      0.995      0.848\n","                obj_13        979        979          1      0.932      0.995      0.791\n","                obj_14       1042       1042      0.986      0.995      0.994      0.848\n","                obj_15       1041       1041      0.985        0.9      0.989      0.786\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train2222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 210.9Â±71.9 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 147.7Â±58.7 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.4125     0.4948     0.8297         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.977      0.973      0.992      0.811\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train2222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.977      0.972      0.992      0.811\n","                obj_01       1050       1050      0.997      0.947      0.994       0.83\n","                obj_02       1031       1031      0.979      0.975      0.992      0.787\n","                obj_04       1020       1020      0.929      0.974      0.988      0.733\n","                obj_05       1016       1016      0.979      0.991      0.994      0.808\n","                obj_06       1002       1002      0.989      0.938      0.992      0.839\n","                obj_08       1009       1009      0.985      0.924       0.99      0.804\n","                obj_09       1065       1065      0.974      0.988      0.992       0.83\n","                obj_10       1065       1065       0.98      0.992      0.995      0.865\n","                obj_11       1036       1036       0.97       0.96      0.989      0.745\n","                obj_12       1051       1051      0.993      0.983      0.995       0.85\n","                obj_13        979        979      0.988      0.984      0.995      0.809\n","                obj_14       1042       1042      0.987      0.995      0.995      0.848\n","                obj_15       1041       1041      0.954      0.991      0.993        0.8\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train22222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 197.1Â±68.3 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.7Â±0.3 ms, read: 164.2Â±49.7 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train22222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train22222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.4227     0.4789     0.8293         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.972      0.974      0.993      0.845\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train22222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train22222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train22222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.971      0.975      0.993      0.845\n","                obj_01       1050       1050      0.883      0.994       0.99      0.868\n","                obj_02       1031       1031      0.987      0.977      0.993      0.821\n","                obj_04       1020       1020      0.917      0.983      0.991      0.765\n","                obj_05       1016       1016      0.964      0.991      0.994      0.846\n","                obj_06       1002       1002      0.987      0.948      0.992      0.866\n","                obj_08       1009       1009      0.976      0.968      0.991      0.857\n","                obj_09       1065       1065       0.98       0.99      0.991      0.884\n","                obj_10       1065       1065      0.977      0.994      0.994      0.882\n","                obj_11       1036       1036      0.977      0.969      0.993       0.81\n","                obj_12       1051       1051      0.994      0.978      0.995       0.87\n","                obj_13        979        979      0.999      0.997      0.995      0.837\n","                obj_14       1042       1042      0.998      0.984      0.995      0.856\n","                obj_15       1041       1041      0.985      0.904      0.991      0.816\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train22222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.0 ms, read: 235.2Â±90.4 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 1.1Â±1.5 ms, read: 129.0Â±78.7 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3992     0.4525     0.8229         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.973      0.976      0.993      0.849\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.973      0.976      0.993      0.849\n","                obj_01       1050       1050      0.867      0.999      0.993      0.874\n","                obj_02       1031       1031      0.995      0.963      0.994      0.833\n","                obj_04       1020       1020      0.913      0.999      0.992      0.777\n","                obj_05       1016       1016      0.993      0.984      0.995      0.877\n","                obj_06       1002       1002      0.984      0.978      0.993      0.864\n","                obj_08       1009       1009      0.978      0.957      0.992       0.86\n","                obj_09       1065       1065      0.972      0.978       0.99      0.876\n","                obj_10       1065       1065      0.978      0.993      0.994      0.875\n","                obj_11       1036       1036      0.992      0.902      0.992      0.818\n","                obj_12       1051       1051      0.996      0.963      0.994      0.858\n","                obj_13        979        979      0.995      0.997      0.995      0.835\n","                obj_14       1042       1042      0.997      0.993      0.995      0.858\n","                obj_15       1041       1041      0.988      0.976      0.994       0.83\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train2222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 165.3Â±108.2 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.4Â±0.1 ms, read: 184.0Â±74.6 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3613     0.4227     0.8169         15        640: 100%|ââââââââââ| 150/150 [00:18<00:00,  8.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.977      0.978      0.993      0.849\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train2222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.977      0.978      0.993      0.849\n","                obj_01       1050       1050      0.971      0.989      0.994      0.871\n","                obj_02       1031       1031      0.981      0.987      0.994      0.838\n","                obj_04       1020       1020      0.949      0.995      0.993      0.789\n","                obj_05       1016       1016      0.963      0.991      0.993      0.872\n","                obj_06       1002       1002      0.984      0.959      0.991      0.858\n","                obj_08       1009       1009      0.987      0.889      0.983      0.849\n","                obj_09       1065       1065      0.973       0.99      0.994      0.881\n","                obj_10       1065       1065      0.986      0.993      0.995      0.878\n","                obj_11       1036       1036       0.97      0.978      0.992      0.806\n","                obj_12       1051       1051      0.994      0.969      0.995      0.855\n","                obj_13        979        979      0.996      0.996      0.995      0.843\n","                obj_14       1042       1042      0.997      0.991      0.995      0.863\n","                obj_15       1041       1041      0.954      0.988      0.992      0.834\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train22222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 180.2Â±58.7 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.4Â±0.1 ms, read: 153.3Â±67.8 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train22222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train22222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3391     0.3975     0.8122         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.986       0.98      0.994      0.849\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train22222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train22222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train22222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.986       0.98      0.994      0.848\n","                obj_01       1050       1050      0.977       0.99      0.994      0.859\n","                obj_02       1031       1031      0.983      0.991      0.995      0.833\n","                obj_04       1020       1020      0.965       0.99      0.994      0.811\n","                obj_05       1016       1016      0.992      0.999      0.995      0.871\n","                obj_06       1002       1002      0.998      0.922      0.993      0.858\n","                obj_08       1009       1009      0.988       0.96      0.992      0.855\n","                obj_09       1065       1065      0.978       0.98      0.993      0.867\n","                obj_10       1065       1065      0.996      0.987      0.995      0.874\n","                obj_11       1036       1036      0.984      0.972      0.994      0.797\n","                obj_12       1051       1051      0.997      0.967      0.995      0.853\n","                obj_13        979        979          1      0.988      0.995      0.842\n","                obj_14       1042       1042      0.988      0.997      0.995      0.869\n","                obj_15       1041       1041      0.969      0.998      0.994       0.84\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train22222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.0 ms, read: 235.8Â±87.5 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 192.6Â±29.2 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3417     0.3819     0.8124         15        640: 100%|ââââââââââ| 150/150 [00:19<00:00,  7.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407       0.98      0.977      0.993      0.841\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.979      0.977      0.993      0.841\n","                obj_01       1050       1050      0.971      0.981      0.993      0.852\n","                obj_02       1031       1031      0.995      0.951       0.99      0.821\n","                obj_04       1020       1020      0.964      0.996      0.994      0.811\n","                obj_05       1016       1016      0.974      0.991      0.994      0.861\n","                obj_06       1002       1002      0.997      0.932      0.992      0.855\n","                obj_08       1009       1009      0.956      0.974      0.991      0.849\n","                obj_09       1065       1065      0.979      0.978      0.993       0.85\n","                obj_10       1065       1065      0.961      0.996      0.995      0.884\n","                obj_11       1036       1036      0.986      0.937      0.991      0.775\n","                obj_12       1051       1051      0.987      0.989      0.995      0.846\n","                obj_13        979        979      0.999      0.995      0.995      0.835\n","                obj_14       1042       1042      0.994      0.994      0.995      0.865\n","                obj_15       1041       1041       0.97      0.989      0.993      0.824\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train2222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 199.4Â±70.9 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 174.8Â±33.0 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3503     0.3757     0.8136         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407       0.98      0.982      0.994      0.851\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train2222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.981      0.982      0.994      0.851\n","                obj_01       1050       1050      0.923      0.993      0.992      0.859\n","                obj_02       1031       1031      0.985      0.977       0.99      0.822\n","                obj_04       1020       1020      0.943      0.993      0.992       0.82\n","                obj_05       1016       1016      0.994      0.986      0.995      0.855\n","                obj_06       1002       1002      0.995       0.97      0.994       0.87\n","                obj_08       1009       1009      0.976       0.97      0.993      0.856\n","                obj_09       1065       1065      0.979      0.992      0.994      0.865\n","                obj_10       1065       1065      0.986      0.989      0.995      0.892\n","                obj_11       1036       1036      0.978      0.978      0.994      0.793\n","                obj_12       1051       1051      0.996      0.974      0.995      0.871\n","                obj_13        979        979      0.998      0.985      0.995      0.837\n","                obj_14       1042       1042      0.999       0.98      0.995      0.876\n","                obj_15       1041       1041      0.997      0.978      0.995      0.847\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train22222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.0 ms, read: 237.4Â±90.5 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 208.5Â±38.3 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train22222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train22222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3433     0.3657     0.8133         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407       0.97      0.973      0.992      0.853\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train22222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train22222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train22222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407       0.97      0.973      0.992      0.853\n","                obj_01       1050       1050      0.918      0.996      0.992      0.874\n","                obj_02       1031       1031       0.99      0.942      0.984       0.82\n","                obj_04       1020       1020      0.907      0.997      0.992      0.797\n","                obj_05       1016       1016      0.994      0.976      0.993      0.875\n","                obj_06       1002       1002      0.993      0.947      0.992      0.864\n","                obj_08       1009       1009      0.984      0.896      0.983      0.855\n","                obj_09       1065       1065      0.939      0.998      0.991      0.879\n","                obj_10       1065       1065      0.951      0.995      0.995      0.878\n","                obj_11       1036       1036      0.963      0.986      0.993      0.805\n","                obj_12       1051       1051      0.991      0.976      0.994      0.866\n","                obj_13        979        979      0.996      0.992      0.995      0.842\n","                obj_14       1042       1042          1      0.988      0.995      0.879\n","                obj_15       1041       1041      0.982       0.96      0.993      0.851\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train22222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train222222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train222222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 259.5Â±34.4 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.6Â±0.5 ms, read: 133.6Â±59.7 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train222222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train222222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3555     0.3598     0.8137         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.977      0.977      0.993      0.833\n","\n","1 epochs completed in 0.026 hours.\n","Optimizer stripped from runs/detect/train222222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train222222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train222222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.977      0.977      0.993      0.833\n","                obj_01       1050       1050      0.979      0.975      0.994      0.847\n","                obj_02       1031       1031      0.983      0.984      0.994      0.811\n","                obj_04       1020       1020      0.959      0.986      0.992      0.776\n","                obj_05       1016       1016      0.989      0.983      0.994      0.852\n","                obj_06       1002       1002      0.975      0.938      0.989      0.838\n","                obj_08       1009       1009      0.979      0.938      0.985      0.826\n","                obj_09       1065       1065      0.913      0.995       0.99      0.841\n","                obj_10       1065       1065      0.997      0.979      0.994      0.855\n","                obj_11       1036       1036       0.98      0.973      0.993      0.784\n","                obj_12       1051       1051      0.997      0.979      0.995      0.855\n","                obj_13        979        979      0.998       0.98      0.995      0.833\n","                obj_14       1042       1042      0.994      0.991      0.995      0.865\n","                obj_15       1041       1041      0.958          1      0.994      0.842\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train222222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2222222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train2222222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.0 ms, read: 219.9Â±81.0 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.6Â±0.1 ms, read: 178.2Â±53.3 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2222222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2222222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3466     0.3494     0.8128         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.976      0.975      0.992      0.829\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train2222222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2222222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2222222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.977      0.975      0.992      0.828\n","                obj_01       1050       1050      0.985      0.965      0.993      0.842\n","                obj_02       1031       1031      0.984       0.99      0.994      0.806\n","                obj_04       1020       1020      0.987      0.964      0.993      0.786\n","                obj_05       1016       1016      0.961      0.986      0.993      0.851\n","                obj_06       1002       1002      0.932      0.991      0.993      0.835\n","                obj_08       1009       1009      0.986      0.867       0.98      0.825\n","                obj_09       1065       1065      0.971      0.995      0.994      0.848\n","                obj_10       1065       1065       0.98      0.989      0.994      0.853\n","                obj_11       1036       1036      0.975      0.964      0.991      0.791\n","                obj_12       1051       1051       0.99      0.989      0.995      0.838\n","                obj_13        979        979      0.999      0.979      0.995      0.822\n","                obj_14       1042       1042      0.993      0.994      0.995      0.853\n","                obj_15       1041       1041      0.952      0.998      0.992       0.82\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2222222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22222222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train22222222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.0 ms, read: 157.5Â±110.8 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.5Â±0.1 ms, read: 191.9Â±53.9 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train22222222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train22222222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3247     0.3352     0.8094         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:09<00:00,  5.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.975      0.977      0.993      0.826\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train22222222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train22222222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train22222222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.975      0.977      0.993      0.826\n","                obj_01       1050       1050      0.993       0.96      0.994      0.826\n","                obj_02       1031       1031      0.992      0.973      0.994      0.787\n","                obj_04       1020       1020      0.986      0.938      0.992      0.788\n","                obj_05       1016       1016      0.934      0.989      0.991      0.863\n","                obj_06       1002       1002      0.964      0.989      0.994      0.836\n","                obj_08       1009       1009      0.957       0.95      0.983      0.843\n","                obj_09       1065       1065      0.978      0.981      0.994      0.821\n","                obj_10       1065       1065      0.953      0.994      0.995      0.864\n","                obj_11       1036       1036      0.966      0.974      0.991      0.773\n","                obj_12       1051       1051      0.984      0.985      0.994      0.834\n","                obj_13        979        979          1      0.978      0.995      0.835\n","                obj_14       1042       1042      0.986      0.998      0.995      0.851\n","                obj_15       1041       1041      0.984      0.991      0.995       0.82\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train22222222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train222222222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train222222222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.0 ms, read: 240.6Â±93.6 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 1.0Â±0.7 ms, read: 68.1Â±76.4 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train222222222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train222222222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3179     0.3235     0.8077         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.982      0.976      0.993      0.836\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train222222222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train222222222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train222222222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.982      0.977      0.993      0.836\n","                obj_01       1050       1050      0.992      0.972      0.994      0.848\n","                obj_02       1031       1031      0.976       0.98      0.993      0.802\n","                obj_04       1020       1020      0.968      0.993      0.993      0.801\n","                obj_05       1016       1016      0.989      0.978      0.994      0.851\n","                obj_06       1002       1002      0.993      0.956      0.992      0.855\n","                obj_08       1009       1009      0.979      0.952      0.987      0.844\n","                obj_09       1065       1065      0.987      0.975      0.994      0.847\n","                obj_10       1065       1065      0.985      0.992      0.995      0.875\n","                obj_11       1036       1036      0.921      0.991      0.993      0.783\n","                obj_12       1051       1051      0.997      0.934      0.993      0.842\n","                obj_13        979        979      0.999      0.989      0.995      0.843\n","                obj_14       1042       1042       0.99      0.998      0.995      0.862\n","                obj_15       1041       1041      0.989      0.984      0.994      0.819\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train222222222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2222222222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train2222222222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.3Â±0.1 ms, read: 220.0Â±78.7 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.4Â±0.0 ms, read: 167.9Â±105.4 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train2222222222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train2222222222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3101     0.3138      0.807         15        640: 100%|ââââââââââ| 150/150 [00:17<00:00,  8.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.959      0.976      0.991      0.844\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train2222222222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train2222222222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train2222222222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.959      0.975      0.991      0.845\n","                obj_01       1050       1050      0.899       0.99      0.978       0.84\n","                obj_02       1031       1031      0.993      0.953      0.991      0.818\n","                obj_04       1020       1020       0.99      0.916      0.992       0.81\n","                obj_05       1016       1016      0.945      0.986      0.988      0.847\n","                obj_06       1002       1002      0.966      0.987      0.994      0.865\n","                obj_08       1009       1009      0.941      0.981      0.987      0.861\n","                obj_09       1065       1065      0.962      0.995      0.993      0.859\n","                obj_10       1065       1065      0.897      0.995      0.993      0.882\n","                obj_11       1036       1036      0.896      0.993      0.989      0.781\n","                obj_12       1051       1051       0.99      0.989      0.995      0.863\n","                obj_13        979        979          1      0.974      0.995       0.83\n","                obj_14       1042       1042      0.996       0.97      0.995      0.876\n","                obj_15       1041       1041      0.997       0.95      0.994      0.846\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train2222222222222222222\u001b[0m\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/DatasetCorrect_TrainingYOLO/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/RetrainedYOLO_Models_Correct/YOLO_retrained_10.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train22222222222222222222, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=False, save_conf=False, save_crop=False, save_dir=runs/detect/train22222222222222222222, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    754432  ultralytics.nn.modules.head.Detect           [16, [64, 128, 256]]          \n","Model summary: 129 layers, 3,013,968 parameters, 3,013,952 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed â\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access â (ping: 0.2Â±0.0 ms, read: 227.3Â±81.7 MB/s, size: 450.2 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/train.cache... 2393 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 2393/2393 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access â (ping: 0.4Â±0.0 ms, read: 153.6Â±86.8 MB/s, size: 451.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/DatasetCorrect_TrainingYOLO/labels/val.cache... 13407 images, 0 backgrounds, 0 corrupt: 100%|ââââââââââ| 13407/13407 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train22222222222222222222/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/train22222222222222222222\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      2.17G     0.3183     0.3107     0.8085         15        640: 100%|ââââââââââ| 150/150 [00:18<00:00,  8.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:10<00:00,  5.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.978      0.973      0.993      0.841\n","\n","1 epochs completed in 0.025 hours.\n","Optimizer stripped from runs/detect/train22222222222222222222/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train22222222222222222222/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train22222222222222222222/weights/best.pt...\n","Ultralytics 8.3.139 ð Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,008,768 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|ââââââââââ| 419/419 [01:03<00:00,  6.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all      13407      13407      0.978      0.973      0.993      0.841\n","                obj_01       1050       1050      0.996      0.946      0.994       0.85\n","                obj_02       1031       1031      0.995      0.962      0.992      0.817\n","                obj_04       1020       1020      0.973      0.955       0.99      0.772\n","                obj_05       1016       1016      0.951      0.994      0.989      0.854\n","                obj_06       1002       1002      0.991      0.976      0.994      0.855\n","                obj_08       1009       1009      0.971      0.966      0.991       0.86\n","                obj_09       1065       1065      0.989      0.972      0.994      0.857\n","                obj_10       1065       1065      0.997      0.968      0.995      0.887\n","                obj_11       1036       1036      0.974      0.947      0.988      0.783\n","                obj_12       1051       1051      0.899      0.999      0.994      0.863\n","                obj_13        979        979      0.996      0.995      0.995      0.831\n","                obj_14       1042       1042      0.999       0.99      0.995      0.877\n","                obj_15       1041       1041      0.979      0.979      0.994      0.826\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train22222222222222222222\u001b[0m\n"]}]},{"cell_type":"code","source":["print(\"â Addestramento completato. Puoi disconnettere il runtime.\")\n","os.kill(os.getpid(), 9)"],"metadata":{"id":"teePIaNbQj55"},"execution_count":null,"outputs":[]}]}